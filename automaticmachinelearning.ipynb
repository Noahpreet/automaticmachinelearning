{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ff50481",
      "metadata": {
        "id": "0ff50481"
      },
      "outputs": [],
      "source": [
        "#Analyzing the dataset\n",
        "from scipy.stats import shapiro\n",
        "import pandas as pd\n",
        "\n",
        "CONFIG_MAX_DUMMY = \"max_dummy\"\n",
        "CONFIG_MAX_DUMMY_PCT = \"pct_dummy\"\n",
        "\n",
        "CONFIG = {\n",
        "  CONFIG_MAX_DUMMY: 1000,\n",
        "  CONFIG_MAX_DUMMY_PCT: 0.75\n",
        "}\n",
        "\n",
        "def isnumeric(datatype):\n",
        "  return datatype in [FIELD_TYPE_FLOAT,FIELD_TYPE_INT]\n",
        "\n",
        "FIELDS = \"fields\"\n",
        "FIELD_ACTION = \"action\"\n",
        "FIELD_ACTION_COPY = \"copy\"\n",
        "FIELD_ACTION_IGNORE = \"ignore\"\n",
        "FIELD_ACTION_ZSCORE = \"zscore\"\n",
        "FIELD_ACTION_NORMALIZE = \"normalize\"\n",
        "FIELD_ACTION_DUMMY = \"dummy\"\n",
        "FIELD_ACTION_TARGET = \"target\"\n",
        "FIELD_NAME = \"name\"\n",
        "FIELD_SUM = \"sum\"\n",
        "FIELD_TYPE = \"type\"\n",
        "FIELD_MEAN = \"mean\"\n",
        "FIELD_NUM = \"n\"\n",
        "FIELD_MISSING = \"missing\"\n",
        "FIELD_MIN = \"min\"\n",
        "FIELD_MAX = \"max\"\n",
        "FIELD_VAR = \"var\"\n",
        "FIELD_SD = \"sd\"\n",
        "FIELD_UNIQUE = \"unique\"\n",
        "FIELD_MEDIAN = \"median\"\n",
        "FIELD_MODE = \"mode\"\n",
        "FIELD_SHAPIRO_STAT = \"shapiro-stat\"\n",
        "FIELD_SHAPIRO_P = \"shapiro-p\"\n",
        "META_TARGET = \"target\"\n",
        "META_TYPE = \"type\"\n",
        "META_TYPE_BINARY_CLASSIFICATION = \"binary-classification\"\n",
        "META_TYPE_CLASSIFICATION = \"classification\"\n",
        "META_TYPE_REGRESSION = \"regression\"\n",
        "META_SOURCE = \"source\"\n",
        "META_POSITIVE_TOKEN = \"positive-token\"\n",
        "META_EARLY_STOP = \"early-stop\"\n",
        "\n",
        "FIELD_TYPE_FLOAT = \"float\"\n",
        "FIELD_TYPE_INT = \"int\"\n",
        "FIELD_TYPE_STR = \"str\"\n",
        "\n",
        "def find_positive(s):\n",
        "  s = set(s.str.upper().tolist())\n",
        "  if len(s) != 2: return None\n",
        "  if \"+\" in s and \"-\" in s: return \"+\"\n",
        "  if \"0\" in s and \"1\" in s: return \"1\"\n",
        "  if \"t\" in s and \"f\" in s: return \"t\"\n",
        "  if \"y\" in s and \"n\" in s: return \"y\"\n",
        "  if \"true\" in s and \"false\" in s: return \"true\"\n",
        "  if \"yes\" in s and \"no\" in s: return \"yes\"\n",
        "  if \"p\" in s and \"n\" in s: return \"p\"\n",
        "  if \"positive\" in s and \"negative\" in s: return \"positive\"\n",
        "  s = list(s)\n",
        "  s.sort()\n",
        "  return s[0]\n",
        "\n",
        "def analyze(data_source, target, is_regression=True):\n",
        "  df = pd.read_csv(data_source,na_values=['NA', '?'])\n",
        "\n",
        "  metadata = {\n",
        "      FIELDS: {},\n",
        "      META_TARGET: target,\n",
        "      META_SOURCE: data_source,\n",
        "      META_EARLY_STOP: True\n",
        "  }\n",
        "\n",
        "  fields = metadata[FIELDS]\n",
        "\n",
        "  for field_name,csv_type in zip(df.columns,df.dtypes):\n",
        "    #print(name,csv_type)\n",
        "    if \"float\" in csv_type.name:\n",
        "      dtype = FIELD_TYPE_FLOAT\n",
        "      action = FIELD_ACTION_COPY\n",
        "    elif \"int\" in csv_type.name:\n",
        "      dtype = FIELD_TYPE_INT\n",
        "      action = FIELD_ACTION_COPY\n",
        "    else:\n",
        "      dtype = FIELD_TYPE_STR\n",
        "      action = FIELD_ACTION_IGNORE\n",
        "\n",
        "    missing_count = sum(df[field_name].isnull())\n",
        "    col = df[field_name]\n",
        "    unique_count = len(pd.unique(col))\n",
        "\n",
        "    if isnumeric(dtype):\n",
        "      stat, p = shapiro(col)\n",
        "\n",
        "      # less than or equal to 0.05 not normal\n",
        "      action = FIELD_ACTION_ZSCORE if p>0.05 else FIELD_ACTION_NORMALIZE\n",
        "\n",
        "      fields[field_name] = {\n",
        "          FIELD_TYPE:dtype,\n",
        "          FIELD_MEDIAN:col.median(),\n",
        "          FIELD_MEAN:col.mean(),\n",
        "          FIELD_SD:col.std(),\n",
        "          FIELD_MAX:col.max(),\n",
        "          FIELD_MIN:col.min(),\n",
        "          FIELD_SHAPIRO_STAT:stat,\n",
        "          FIELD_SHAPIRO_P:p,\n",
        "          FIELD_ACTION:action,\n",
        "          FIELD_MISSING:missing_count,\n",
        "          FIELD_UNIQUE:unique_count}\n",
        "\n",
        "    else:\n",
        "      fields[field_name] = {\n",
        "          FIELD_TYPE:dtype,\n",
        "          FIELD_MODE:col.mode()[0],\n",
        "          FIELD_ACTION:action,\n",
        "          FIELD_MISSING:missing_count,\n",
        "          FIELD_UNIQUE:unique_count}\n",
        "\n",
        "    # Determine action\n",
        "    field = fields[field_name]\n",
        "    if (field[FIELD_TYPE] == FIELD_TYPE_STR) and (field[FIELD_UNIQUE]<CONFIG[CONFIG_MAX_DUMMY]) and (field[FIELD_UNIQUE]/len(df)<CONFIG[CONFIG_MAX_DUMMY_PCT]):\n",
        "      field[FIELD_ACTION] = FIELD_ACTION_DUMMY\n",
        "    if field_name == target:\n",
        "      field[FIELD_ACTION] = FIELD_ACTION_TARGET\n",
        "\n",
        "  # Determine model type\n",
        "  is_binary = (metadata[FIELDS][target][FIELD_UNIQUE]==2) and not is_regression\n",
        "\n",
        "  if is_regression:\n",
        "    metadata[META_TYPE] = META_TYPE_REGRESSION\n",
        "  else:\n",
        "    if metadata[FIELDS][target][FIELD_UNIQUE]==2:\n",
        "      metadata[META_TYPE] = META_TYPE_BINARY_CLASSIFICATION\n",
        "\n",
        "      metadata[META_POSITIVE_TOKEN] = find_positive(df[target])\n",
        "    else:\n",
        "      metadata[META_TYPE] = META_TYPE_CLASSIFICATION\n",
        "\n",
        "  return metadata\n",
        "\n",
        "COLS = [FIELD_MEAN, FIELD_SD, FIELD_MEDIAN, FIELD_MODE, FIELD_MAX, FIELD_ACTION, FIELD_UNIQUE, FIELD_SHAPIRO_P,FIELD_MISSING]\n",
        "\n",
        "def field_summary(metadata, cols=COLS):\n",
        "  data = {}\n",
        "\n",
        "  data['name'] = []\n",
        "  for col in cols:\n",
        "    data[col] = []\n",
        "\n",
        "  for field_name in metadata[FIELDS]:\n",
        "    field = metadata[FIELDS][field_name]\n",
        "    data['name'].append(field_name)\n",
        "    for col in cols:\n",
        "      data[col].append(field.get(col, None))\n",
        "\n",
        "  return pd.DataFrame(data)[['name']+COLS]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64818168",
      "metadata": {
        "id": "64818168"
      },
      "outputs": [],
      "source": [
        "#generating the code\n",
        "from dataclasses import MISSING\n",
        "from pandas.core.dtypes.inference import is_re\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def tolist(obj):\n",
        "    if isinstance(obj, list) or isinstance(obj, tuple):\n",
        "        return obj\n",
        "    else:\n",
        "        return [obj]\n",
        "\n",
        "class PythonFile:\n",
        "    def __init__(self):\n",
        "        self.imports = []\n",
        "        self.lines = []\n",
        "\n",
        "    def add_import(self, name, alias=None):\n",
        "        if alias:\n",
        "            self.imports.append({\"name\": name, \"alias\": alias})\n",
        "        else:\n",
        "            self.imports.append({\"name\": name})\n",
        "\n",
        "    def add_from(self, _from, _import):\n",
        "        self.imports.append({\"from\": _from, \"import\": _import})\n",
        "\n",
        "    def generate(self):\n",
        "        src = \"\"\n",
        "        for obj in self.imports:\n",
        "            if \"name\" in obj and \"alias\" in obj:\n",
        "                src += f\"import {obj['name']} as {obj['alias']}\"\n",
        "            elif \"name\" in obj and \"alias\" not in obj:\n",
        "                src += f\"import {obj['name']}\"\n",
        "            elif \"from\" in obj and \"import\" in obj:\n",
        "                imports = \", \".join(tolist(obj['import']))\n",
        "                src += f\"from {obj['from']} import {imports}\"\n",
        "\n",
        "            src += \"\\n\"\n",
        "\n",
        "        for line in self.lines:\n",
        "            src += line + \"\\n\"\n",
        "        return src\n",
        "\n",
        "    def add_line(self, str):\n",
        "        self.lines.append(str)\n",
        "\n",
        "    def comment(self, str):\n",
        "        return f\"# {str}\"\n",
        "\n",
        "    def call(self, name, *args):\n",
        "        src = name + \"(\"\n",
        "\n",
        "        formatted_args = []\n",
        "        started_named = False\n",
        "        for arg in args:\n",
        "            if isinstance(arg, dict):\n",
        "                formatted_args += [f\"{name}={arg[name]}\" for name in arg.keys()]\n",
        "                started_named = True\n",
        "            else:\n",
        "                if started_named:\n",
        "                    raise ValueError(\"positional argument follows keyword argument\")\n",
        "                formatted_args.append(str(arg))\n",
        "\n",
        "        src += \", \".join(formatted_args)\n",
        "        src += \")\"\n",
        "        return src\n",
        "\n",
        "    def assign(self, left, right):\n",
        "        return f\"{left} = {right}\"\n",
        "\n",
        "    def str(self, str):\n",
        "        return f\"\\\"{str}\\\"\"\n",
        "\n",
        "    def index(self, name, indexes, dot=None):\n",
        "        src = name\n",
        "        for idx in indexes:\n",
        "            src += f'[{idx}]'\n",
        "\n",
        "        if dot:\n",
        "            src += '.'\n",
        "            src += dot\n",
        "        return src\n",
        "\n",
        "def generate_keras(metadata, visualize=True, pca_components=None):\n",
        "    na_values = ['NA', '?']\n",
        "    target = metadata[META_TARGET]\n",
        "    is_regression = metadata[META_TYPE] == META_TYPE_REGRESSION\n",
        "    is_binary = (metadata[FIELDS][target][FIELD_UNIQUE] == 2) and (metadata[META_TYPE] == META_TYPE_CLASSIFICATION)\n",
        "\n",
        "    if metadata[META_TYPE] == META_TYPE_REGRESSION:\n",
        "        loss = \"mean_squared_error\"\n",
        "    elif metadata[META_TYPE] == META_TYPE_BINARY_CLASSIFICATION:\n",
        "        loss = \"binary_crossentropy\"\n",
        "    else:\n",
        "        loss = \"categorical_crossentropy\"\n",
        "\n",
        "    py = PythonFile()\n",
        "    # Imports\n",
        "    py.add_import(\"pandas\", \"pd\")\n",
        "    py.add_import(\"io\")\n",
        "    py.add_import(\"requests\")\n",
        "    py.add_import(\"numpy\", \"np\")\n",
        "    py.add_from(\"tensorflow.keras.models\", \"Sequential\")\n",
        "    py.add_from(\"tensorflow.keras.layers\", [\"Dense\", \"Activation\"])\n",
        "    py.add_from(\"tensorflow.keras.callbacks\", \"EarlyStopping\")\n",
        "    py.add_from(\"scipy.stats\", \"zscore\")\n",
        "    py.add_from(\"sklearn.preprocessing\", \"MinMaxScaler\")\n",
        "    py.add_from(\"sklearn.model_selection\", \"train_test_split\")\n",
        "    py.add_from(\"sklearn.metrics\", [\"accuracy_score\", \"mean_squared_error\", \"log_loss\", \"roc_curve\", \"auc\"])\n",
        "    if visualize:\n",
        "        py.add_import(\"matplotlib.pyplot\", \"plt\")\n",
        "    if pca_components:\n",
        "        py.add_import(\"sklearn.decomposition\", \"PCA\")\n",
        "\n",
        "    py.add_line(py.assign(\"df\", py.call(\"pd.read_csv\", py.str(metadata[META_SOURCE]), {'na_values': na_values})))\n",
        "    x_fields = [x for x in metadata[FIELDS] if x != target and metadata[FIELDS][x][FIELD_ACTION] in [FIELD_ACTION_COPY]]\n",
        "    py.add_line(py.assign(\"x_fields\", x_fields))\n",
        "\n",
        "    # Analyze input columns\n",
        "    for field_name in metadata[FIELDS]:\n",
        "        field = metadata[FIELDS][field_name]\n",
        "        if field[FIELD_MISSING] > 0:\n",
        "            if isnumeric(field[FIELD_TYPE]):\n",
        "                fn = \"median\"\n",
        "                suffix = \"\"\n",
        "            else:\n",
        "                fn = \"mode\"\n",
        "                suffix = \"[0]\"\n",
        "            py.add_line(py.assign(py.index(\"df\", [py.str(field_name)]),\n",
        "                                  py.index(\"df\", [py.str(field_name)], py.call(\"fillna\",\n",
        "                                                                           py.index(\"df\", [py.str(field_name)],\n",
        "                                                                                    py.call(fn) + suffix)\n",
        "                                                                           ))))\n",
        "        if field[FIELD_ACTION] == FIELD_ACTION_ZSCORE:\n",
        "            py.add_line(py.assign(py.index(\"df\", [py.str(field_name)]),\n",
        "                                  py.call(\"zscore\", py.index(\"df\", [py.str(field_name)]))))\n",
        "            py.add_line(py.call(\"x_fields.append\", py.str(field_name)))\n",
        "        elif field[FIELD_ACTION] == FIELD_ACTION_NORMALIZE:\n",
        "            f1 = py.index(\"df\", [py.str(field_name)])\n",
        "            f2 = py.index(\"df\", [[field_name]])\n",
        "            py.add_line(py.assign(f1, py.call(\"MinMaxScaler().fit_transform\", f2)))\n",
        "            py.add_line(py.call(\"x_fields.append\", py.str(field_name)))\n",
        "        elif field[FIELD_ACTION] == FIELD_ACTION_DUMMY:\n",
        "            py.add_line(py.assign(\"dummies\",\n",
        "                                  py.call(\"pd.get_dummies\",\n",
        "                                          py.index('df', [py.str(field_name)]),\n",
        "                                          {'prefix': py.str(field_name), 'drop_first': 'True'})))\n",
        "            py.add_line(\"df = pd.concat([df,dummies],axis=1)\")\n",
        "            py.add_line(\"x_fields += dummies.columns.tolist()\")\n",
        "\n",
        "    py.add_line(py.assign(\"x\", py.index(\"df\", [\"x_fields\"], \"values\")))\n",
        "\n",
        "    if metadata[META_TYPE] == META_TYPE_CLASSIFICATION:\n",
        "        py.add_line(py.assign(\"dummies\", py.call(\"pd.get_dummies\", py.index(\"df\", [py.str(target)]))))\n",
        "        py.add_line(py.assign(\"species\", \"dummies.columns\"))\n",
        "        py.add_line(py.assign(\"y\", \"dummies.values\"))\n",
        "    elif metadata[META_TYPE] == META_TYPE_BINARY_CLASSIFICATION:\n",
        "        t = py.index(\"df\", [py.str(target)])\n",
        "        pos = metadata[META_POSITIVE_TOKEN]\n",
        "        py.add_line(py.assign(t, f\"({t}=={py.str(pos)}).astype(int)\"))\n",
        "        py.add_line(py.assign(\"y\", f\"df.{target}.values\"))\n",
        "    else:\n",
        "        py.add_line(py.assign(\"y\", f\"df.{target}.values\"))\n",
        "\n",
        "    py.add_line(py.comment(\"Construct model\"))\n",
        "    # Early stop\n",
        "    if metadata[META_EARLY_STOP]:\n",
        "        x_train, y_train, x_test, y_test = \"x_train\", \"y_train\", \"x_test\", \"y_test\"\n",
        "        py.add_line(py.comment(\"Split into validation and training sets\"))\n",
        "        py.add_line(py.assign(f\"{x_train}, {x_test}, {y_train}, {y_test}\",\n",
        "                              py.call(\"train_test_split\", \"x\", \"y\", {\"test_size\": 0.25, \"random_state\": 42})))\n",
        "    else:\n",
        "        x_train, y_train, x_test, y_test = \"x\", \"y\", \"x\", \"y\"\n",
        "\n",
        "    py.add_line(py.assign(\"model\", py.call(\"Sequential\")))\n",
        "    py.add_line(py.call(\"model.add\", py.call(\"Dense\", 50, {\"input_dim\": \"x.shape[1]\", \"activation\": py.str('relu')})))\n",
        "    py.add_line(py.call(\"model.add\", py.call(\"Dense\", 25, {\"activation\": py.str('relu')})))\n",
        "    if metadata[META_TYPE] == META_TYPE_REGRESSION:\n",
        "        py.add_line(py.call(\"model.add\", py.call(\"Dense\", \"1\")))\n",
        "    elif metadata[META_TYPE] == META_TYPE_BINARY_CLASSIFICATION:\n",
        "        py.add_line(py.call(\"model.add\", py.call(\"Dense\", \"1\", {\"activation\": py.str('sigmoid')})))\n",
        "    else:\n",
        "        py.add_line(\n",
        "            py.call(\"model.add\", py.call(\"Dense\", \"y.shape[1]\", {\"activation\": py.str('softmax')})))\n",
        "    py.add_line(py.call(\"model.compile\", {\"loss\": py.str(loss), \"optimizer\": py.str('adam')}))\n",
        "\n",
        "    py.add_line(py.comment(\"Train model\"))\n",
        "    if metadata[META_EARLY_STOP]:\n",
        "        py.add_line(py.assign(\"monitor\", py.call(\"EarlyStopping\", {\"monitor\": py.str('val_loss'), \"min_delta\": \"1e-3\",\n",
        "                                                                   \"patience\": 5,\n",
        "                                                                   \"verbose\": 1, \"mode\": py.str('auto'),\n",
        "                                                                   \"restore_best_weights\": True})))\n",
        "        py.add_line(py.call(\"model.fit\", x_train, y_train,\n",
        "                            {\"validation_data\": f\"({x_test},{y_test})\", 'callbacks': '[monitor]', 'verbose': '2',\n",
        "                             'epochs': 1000}))\n",
        "    else:\n",
        "        py.add_line(py.call(\"model.fit\", x_train, y_train, {'verbose': '2', 'epochs': 100}))\n",
        "\n",
        "    py.add_line(py.comment(\"Evaluate model\"))\n",
        "    py.add_line(py.assign(\"pred\", py.call(\"model.predict\", x_test)))\n",
        "    if metadata[META_TYPE] == META_TYPE_REGRESSION:\n",
        "        py.add_line(py.comment(\"Measure RMSE error.  RMSE is common for regression.\"))\n",
        "        py.add_line(py.assign(\"score\", py.call(\"np.sqrt\", py.call(\"metrics.mean_squared_error\", \"pred\", y_test))))\n",
        "        py.add_line(\"print(f\\\"Root mean square (RMSE): {score}\\\")\")\n",
        "    if metadata[META_TYPE] == META_TYPE_CLASSIFICATION:\n",
        "        py.add_line(py.assign(\"predict_classes\", py.call(\"np.argmax\", \"pred\", {\"axis\": 1})))\n",
        "        py.add_line(py.assign(\"expected_classes\", py.call(\"np.argmax\", y_test, {\"axis\": 1})))\n",
        "        py.add_line(py.assign(\"correct\", py.call(\"accuracy_score\", \"expected_classes\", \"predict_classes\")))\n",
        "        py.add_line(\"print(f\\\"Accuracy: {correct}\\\")\")\n",
        "    elif metadata[META_TYPE] == META_TYPE_BINARY_CLASSIFICATION:\n",
        "        py.add_line(py.assign(\"predict_classes\", py.call(\"np.argmax\", \"pred\", {\"axis\": 1})))\n",
        "        py.add_line(py.assign(\"correct\", py.call(\"accuracy_score\", y_test, \"predict_classes\")))\n",
        "        py.add_line(\"print(f\\\"Accuracy: {correct}\\\")\")\n",
        "        py.add_line(py.assign(\"fpr, tpr, thresholds\",\n",
        "                              py.call(\"metrics.roc_curve\", y_test, \"pred\", {\"pos_label\": 1})))\n",
        "        py.add_line(py.assign(\"score\", py.call(\"metrics.auc\", \"fpr\", \"tpr\")))\n",
        "        py.add_line(\"print(f\\\"Area Under Curve: {score}\\\")\")\n",
        "    if metadata[META_TYPE] == META_TYPE_CLASSIFICATION or metadata[META_TYPE] == META_TYPE_BINARY_CLASSIFICATION:\n",
        "        py.add_line(py.assign(\"score\", py.call(\"metrics.log_loss\", y_test, \"pred\", {'eps': 1e-7})))\n",
        "        py.add_line(\"print(f\\\"Log loss: {score}\\\")\")\n",
        "\n",
        "\n",
        "    return py.generate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83f6f2d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "83f6f2d2",
        "outputId": "c89376f0-89c4-447e-be8c-860414528a99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fields': {'crim': {'type': 'float', 'median': 0.25651, 'mean': 3.613523557312254, 'sd': 8.60154510533249, 'max': 88.9762, 'min': 0.00632, 'shapiro-stat': 0.44996488094329834, 'shapiro-p': 1.3285678005931464e-36, 'action': 'normalize', 'missing': 0, 'unique': 504}, 'zn': {'type': 'float', 'median': 0.0, 'mean': 11.363636363636363, 'sd': 23.32245299451514, 'max': 100.0, 'min': 0.0, 'shapiro-stat': 0.5559463500976562, 'shapiro-p': 7.882576753156324e-34, 'action': 'normalize', 'missing': 0, 'unique': 26}, 'indus': {'type': 'float', 'median': 9.69, 'mean': 11.13677865612648, 'sd': 6.860352940897585, 'max': 27.74, 'min': 0.46, 'shapiro-stat': 0.8997918367385864, 'shapiro-p': 1.0642375893751083e-17, 'action': 'normalize', 'missing': 0, 'unique': 76}, 'chas': {'type': 'int', 'median': 0.0, 'mean': 0.0691699604743083, 'sd': 0.25399404134041037, 'max': 1, 'min': 0, 'shapiro-stat': 0.27476072311401367, 'shapiro-p': 2.350467979135232e-40, 'action': 'normalize', 'missing': 0, 'unique': 2}, 'nox': {'type': 'float', 'median': 0.538, 'mean': 0.5546950592885376, 'sd': 0.11587767566755595, 'max': 0.871, 'min': 0.385, 'shapiro-stat': 0.9356358051300049, 'shapiro-p': 5.775851259944009e-14, 'action': 'normalize', 'missing': 0, 'unique': 81}, 'rm': {'type': 'float', 'median': 6.2085, 'mean': 6.284634387351779, 'sd': 0.7026171434153233, 'max': 8.78, 'min': 3.561, 'shapiro-stat': 0.9608709812164307, 'shapiro-p': 2.4107271734408187e-10, 'action': 'normalize', 'missing': 0, 'unique': 446}, 'age': {'type': 'float', 'median': 77.5, 'mean': 68.57490118577076, 'sd': 28.148861406903617, 'max': 100.0, 'min': 2.9, 'shapiro-stat': 0.89201420545578, 'shapiro-p': 2.2311304847966706e-18, 'action': 'normalize', 'missing': 0, 'unique': 356}, 'dis': {'type': 'float', 'median': 3.2074499999999997, 'mean': 3.795042687747036, 'sd': 2.105710126627611, 'max': 12.1265, 'min': 1.1296, 'shapiro-stat': 0.9032330513000488, 'shapiro-p': 2.1851281171594835e-17, 'action': 'normalize', 'missing': 0, 'unique': 412}, 'rad': {'type': 'int', 'median': 5.0, 'mean': 9.549407114624506, 'sd': 8.707259384239366, 'max': 24, 'min': 1, 'shapiro-stat': 0.679641842842102, 'shapiro-p': 8.072354053650428e-30, 'action': 'normalize', 'missing': 0, 'unique': 9}, 'tax': {'type': 'int', 'median': 330.0, 'mean': 408.2371541501976, 'sd': 168.53711605495903, 'max': 711, 'min': 187, 'shapiro-stat': 0.8152396082878113, 'shapiro-p': 1.1629790572690724e-23, 'action': 'target', 'missing': 0, 'unique': 66}, 'ptratio': {'type': 'float', 'median': 19.05, 'mean': 18.455533596837945, 'sd': 2.1649455237144406, 'max': 22.0, 'min': 12.6, 'shapiro-stat': 0.9035943746566772, 'shapiro-p': 2.359104548622454e-17, 'action': 'normalize', 'missing': 0, 'unique': 46}, 'b': {'type': 'float', 'median': 391.44, 'mean': 356.6740316205534, 'sd': 91.29486438415783, 'max': 396.9, 'min': 0.32, 'shapiro-stat': 0.47682422399520874, 'shapiro-p': 6.057845995608311e-36, 'action': 'normalize', 'missing': 0, 'unique': 357}, 'lstat': {'type': 'float', 'median': 11.36, 'mean': 12.653063241106722, 'sd': 7.141061511348571, 'max': 37.97, 'min': 1.73, 'shapiro-stat': 0.9369055032730103, 'shapiro-p': 8.285112504911873e-14, 'action': 'normalize', 'missing': 0, 'unique': 455}, 'medv': {'type': 'float', 'median': 21.2, 'mean': 22.532806324110677, 'sd': 9.197104087379818, 'max': 50.0, 'min': 5.0, 'shapiro-stat': 0.9171746969223022, 'shapiro-p': 4.939965499209636e-16, 'action': 'normalize', 'missing': 0, 'unique': 229}}, 'target': 'tax', 'source': 'https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', 'early-stop': True, 'type': 'classification'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       name        mean          sd     median  mode       max     action  \\\n",
              "0      crim    3.613524    8.601545    0.25651  None   88.9762  normalize   \n",
              "1        zn   11.363636   23.322453    0.00000  None  100.0000  normalize   \n",
              "2     indus   11.136779    6.860353    9.69000  None   27.7400  normalize   \n",
              "3      chas    0.069170    0.253994    0.00000  None    1.0000  normalize   \n",
              "4       nox    0.554695    0.115878    0.53800  None    0.8710  normalize   \n",
              "5        rm    6.284634    0.702617    6.20850  None    8.7800  normalize   \n",
              "6       age   68.574901   28.148861   77.50000  None  100.0000  normalize   \n",
              "7       dis    3.795043    2.105710    3.20745  None   12.1265  normalize   \n",
              "8       rad    9.549407    8.707259    5.00000  None   24.0000  normalize   \n",
              "9       tax  408.237154  168.537116  330.00000  None  711.0000     target   \n",
              "10  ptratio   18.455534    2.164946   19.05000  None   22.0000  normalize   \n",
              "11        b  356.674032   91.294864  391.44000  None  396.9000  normalize   \n",
              "12    lstat   12.653063    7.141062   11.36000  None   37.9700  normalize   \n",
              "13     medv   22.532806    9.197104   21.20000  None   50.0000  normalize   \n",
              "\n",
              "    unique     shapiro-p  missing  \n",
              "0      504  1.328568e-36        0  \n",
              "1       26  7.882577e-34        0  \n",
              "2       76  1.064238e-17        0  \n",
              "3        2  2.350468e-40        0  \n",
              "4       81  5.775851e-14        0  \n",
              "5      446  2.410727e-10        0  \n",
              "6      356  2.231130e-18        0  \n",
              "7      412  2.185128e-17        0  \n",
              "8        9  8.072354e-30        0  \n",
              "9       66  1.162979e-23        0  \n",
              "10      46  2.359105e-17        0  \n",
              "11     357  6.057846e-36        0  \n",
              "12     455  8.285113e-14        0  \n",
              "13     229  4.939965e-16        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c7b5681-2dcf-4906-8f17-d5831f011d00\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>mean</th>\n",
              "      <th>sd</th>\n",
              "      <th>median</th>\n",
              "      <th>mode</th>\n",
              "      <th>max</th>\n",
              "      <th>action</th>\n",
              "      <th>unique</th>\n",
              "      <th>shapiro-p</th>\n",
              "      <th>missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>crim</td>\n",
              "      <td>3.613524</td>\n",
              "      <td>8.601545</td>\n",
              "      <td>0.25651</td>\n",
              "      <td>None</td>\n",
              "      <td>88.9762</td>\n",
              "      <td>normalize</td>\n",
              "      <td>504</td>\n",
              "      <td>1.328568e-36</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>zn</td>\n",
              "      <td>11.363636</td>\n",
              "      <td>23.322453</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>None</td>\n",
              "      <td>100.0000</td>\n",
              "      <td>normalize</td>\n",
              "      <td>26</td>\n",
              "      <td>7.882577e-34</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>indus</td>\n",
              "      <td>11.136779</td>\n",
              "      <td>6.860353</td>\n",
              "      <td>9.69000</td>\n",
              "      <td>None</td>\n",
              "      <td>27.7400</td>\n",
              "      <td>normalize</td>\n",
              "      <td>76</td>\n",
              "      <td>1.064238e-17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>chas</td>\n",
              "      <td>0.069170</td>\n",
              "      <td>0.253994</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>None</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>normalize</td>\n",
              "      <td>2</td>\n",
              "      <td>2.350468e-40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>nox</td>\n",
              "      <td>0.554695</td>\n",
              "      <td>0.115878</td>\n",
              "      <td>0.53800</td>\n",
              "      <td>None</td>\n",
              "      <td>0.8710</td>\n",
              "      <td>normalize</td>\n",
              "      <td>81</td>\n",
              "      <td>5.775851e-14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>rm</td>\n",
              "      <td>6.284634</td>\n",
              "      <td>0.702617</td>\n",
              "      <td>6.20850</td>\n",
              "      <td>None</td>\n",
              "      <td>8.7800</td>\n",
              "      <td>normalize</td>\n",
              "      <td>446</td>\n",
              "      <td>2.410727e-10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>age</td>\n",
              "      <td>68.574901</td>\n",
              "      <td>28.148861</td>\n",
              "      <td>77.50000</td>\n",
              "      <td>None</td>\n",
              "      <td>100.0000</td>\n",
              "      <td>normalize</td>\n",
              "      <td>356</td>\n",
              "      <td>2.231130e-18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>dis</td>\n",
              "      <td>3.795043</td>\n",
              "      <td>2.105710</td>\n",
              "      <td>3.20745</td>\n",
              "      <td>None</td>\n",
              "      <td>12.1265</td>\n",
              "      <td>normalize</td>\n",
              "      <td>412</td>\n",
              "      <td>2.185128e-17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>rad</td>\n",
              "      <td>9.549407</td>\n",
              "      <td>8.707259</td>\n",
              "      <td>5.00000</td>\n",
              "      <td>None</td>\n",
              "      <td>24.0000</td>\n",
              "      <td>normalize</td>\n",
              "      <td>9</td>\n",
              "      <td>8.072354e-30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>tax</td>\n",
              "      <td>408.237154</td>\n",
              "      <td>168.537116</td>\n",
              "      <td>330.00000</td>\n",
              "      <td>None</td>\n",
              "      <td>711.0000</td>\n",
              "      <td>target</td>\n",
              "      <td>66</td>\n",
              "      <td>1.162979e-23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ptratio</td>\n",
              "      <td>18.455534</td>\n",
              "      <td>2.164946</td>\n",
              "      <td>19.05000</td>\n",
              "      <td>None</td>\n",
              "      <td>22.0000</td>\n",
              "      <td>normalize</td>\n",
              "      <td>46</td>\n",
              "      <td>2.359105e-17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>b</td>\n",
              "      <td>356.674032</td>\n",
              "      <td>91.294864</td>\n",
              "      <td>391.44000</td>\n",
              "      <td>None</td>\n",
              "      <td>396.9000</td>\n",
              "      <td>normalize</td>\n",
              "      <td>357</td>\n",
              "      <td>6.057846e-36</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>lstat</td>\n",
              "      <td>12.653063</td>\n",
              "      <td>7.141062</td>\n",
              "      <td>11.36000</td>\n",
              "      <td>None</td>\n",
              "      <td>37.9700</td>\n",
              "      <td>normalize</td>\n",
              "      <td>455</td>\n",
              "      <td>8.285113e-14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>medv</td>\n",
              "      <td>22.532806</td>\n",
              "      <td>9.197104</td>\n",
              "      <td>21.20000</td>\n",
              "      <td>None</td>\n",
              "      <td>50.0000</td>\n",
              "      <td>normalize</td>\n",
              "      <td>229</td>\n",
              "      <td>4.939965e-16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c7b5681-2dcf-4906-8f17-d5831f011d00')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4c7b5681-2dcf-4906-8f17-d5831f011d00 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4c7b5681-2dcf-4906-8f17-d5831f011d00');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-19d6481d-b8c3-4298-a090-d3b0b33d39d0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-19d6481d-b8c3-4298-a090-d3b0b33d39d0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-19d6481d-b8c3-4298-a090-d3b0b33d39d0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "summary",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import pandas as pd\n",
            "import io\n",
            "import requests\n",
            "import numpy as np\n",
            "from tensorflow.keras.models import Sequential\n",
            "from tensorflow.keras.layers import Dense, Activation\n",
            "from tensorflow.keras.callbacks import EarlyStopping\n",
            "from scipy.stats import zscore\n",
            "from sklearn.preprocessing import MinMaxScaler\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.metrics import accuracy_score, mean_squared_error, log_loss, roc_curve, auc\n",
            "import matplotlib.pyplot as plt\n",
            "import sklearn.decomposition as PCA\n",
            "df = pd.read_csv(\"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\", na_values=['NA', '?'])\n",
            "x_fields = []\n",
            "df[\"crim\"] = MinMaxScaler().fit_transform(df[['crim']])\n",
            "x_fields.append(\"crim\")\n",
            "df[\"zn\"] = MinMaxScaler().fit_transform(df[['zn']])\n",
            "x_fields.append(\"zn\")\n",
            "df[\"indus\"] = MinMaxScaler().fit_transform(df[['indus']])\n",
            "x_fields.append(\"indus\")\n",
            "df[\"chas\"] = MinMaxScaler().fit_transform(df[['chas']])\n",
            "x_fields.append(\"chas\")\n",
            "df[\"nox\"] = MinMaxScaler().fit_transform(df[['nox']])\n",
            "x_fields.append(\"nox\")\n",
            "df[\"rm\"] = MinMaxScaler().fit_transform(df[['rm']])\n",
            "x_fields.append(\"rm\")\n",
            "df[\"age\"] = MinMaxScaler().fit_transform(df[['age']])\n",
            "x_fields.append(\"age\")\n",
            "df[\"dis\"] = MinMaxScaler().fit_transform(df[['dis']])\n",
            "x_fields.append(\"dis\")\n",
            "df[\"rad\"] = MinMaxScaler().fit_transform(df[['rad']])\n",
            "x_fields.append(\"rad\")\n",
            "df[\"ptratio\"] = MinMaxScaler().fit_transform(df[['ptratio']])\n",
            "x_fields.append(\"ptratio\")\n",
            "df[\"b\"] = MinMaxScaler().fit_transform(df[['b']])\n",
            "x_fields.append(\"b\")\n",
            "df[\"lstat\"] = MinMaxScaler().fit_transform(df[['lstat']])\n",
            "x_fields.append(\"lstat\")\n",
            "df[\"medv\"] = MinMaxScaler().fit_transform(df[['medv']])\n",
            "x_fields.append(\"medv\")\n",
            "x = df[x_fields].values\n",
            "dummies = pd.get_dummies(df[\"tax\"])\n",
            "species = dummies.columns\n",
            "y = dummies.values\n",
            "# Construct model\n",
            "model = Sequential()\n",
            "model.add(Dense(50, input_dim=x.shape[1], activation=\"relu\"))\n",
            "model.add(Dense(25, activation=\"relu\"))\n",
            "model.add(Dense(y.shape[1], activation=\"softmax\"))\n",
            "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
            "# Train model\n",
            "model.fit(x, y, verbose=2, epochs=100)\n",
            "# Evaluate model\n",
            "pred = model.predict(x)\n",
            "predict_classes = np.argmax(pred, axis=1)\n",
            "expected_classes = np.argmax(y, axis=1)\n",
            "correct = accuracy_score(expected_classes, predict_classes)\n",
            "print(f\"Accuracy: {correct}\")\n",
            "score = metrics.log_loss(y, pred, eps=1e-07)\n",
            "print(f\"Log loss: {score}\")\n",
            "# Data Visualization\n",
            "pca = PCA(n_components=2)\n",
            "x_pca = pca.fit_transform(x)\n",
            "plt.figure(figsize=(8,6))()\n",
            "plt.scatter(x_pca[:, 0], x_pca[:, 1], c=y, cmap='viridis')\n",
            "plt.xlabel(\"First Principal Component\")\n",
            "plt.ylabel(\"Second Principal Component\")\n",
            "plt.title(\"PCA Analysis\")\n",
            "plt.colorbar(\"label=species\")\n",
            "plt.show()\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#DATA_SOURCE = \"https://data.heatonresearch.com/data/t81-558/iris.csv\"; TARGET = \"species\";IS_REGRESSION=False\n",
        "from dataclasses import MISSING\n",
        "from pandas.core.dtypes.inference import is_re\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define your data source URL\n",
        "DATA_SOURCE_URL = \"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\"\n",
        "\n",
        "# Define your target variable\n",
        "TARGET = \"tax\"\n",
        "\n",
        "# Define whether it's a regression task\n",
        "IS_REGRESSION = False  # Update according to your task\n",
        "\n",
        "# Fetch data and generate metadata\n",
        "metadata = analyze(DATA_SOURCE_URL, TARGET, IS_REGRESSION)\n",
        "print(metadata)\n",
        "\n",
        "# Generate summary\n",
        "summary = field_summary(metadata)\n",
        "display(summary)\n",
        "\n",
        "# Disable early stopping\n",
        "metadata[META_EARLY_STOP] = False\n",
        "\n",
        "# Generate Python code including data visualizations\n",
        "python_code = generate_keras(metadata, visualize=True, pca_components=2)\n",
        "print(python_code)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d42db58",
      "metadata": {
        "id": "2d42db58",
        "outputId": "c79ca331-be4a-4ac4-cf5f-6bc72f7a252e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.7)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a88d98d",
      "metadata": {
        "id": "6a88d98d",
        "outputId": "0424c6e1-599f-4a5b-c33e-fdd696c8f619",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 - 1s - loss: 1.0683 - 725ms/epoch - 145ms/step\n",
            "Epoch 2/100\n",
            "5/5 - 0s - loss: 1.0272 - 16ms/epoch - 3ms/step\n",
            "Epoch 3/100\n",
            "5/5 - 0s - loss: 0.9927 - 16ms/epoch - 3ms/step\n",
            "Epoch 4/100\n",
            "5/5 - 0s - loss: 0.9596 - 17ms/epoch - 3ms/step\n",
            "Epoch 5/100\n",
            "5/5 - 0s - loss: 0.9277 - 14ms/epoch - 3ms/step\n",
            "Epoch 6/100\n",
            "5/5 - 0s - loss: 0.8971 - 16ms/epoch - 3ms/step\n",
            "Epoch 7/100\n",
            "5/5 - 0s - loss: 0.8668 - 17ms/epoch - 3ms/step\n",
            "Epoch 8/100\n",
            "5/5 - 0s - loss: 0.8393 - 16ms/epoch - 3ms/step\n",
            "Epoch 9/100\n",
            "5/5 - 0s - loss: 0.8101 - 19ms/epoch - 4ms/step\n",
            "Epoch 10/100\n",
            "5/5 - 0s - loss: 0.7820 - 19ms/epoch - 4ms/step\n",
            "Epoch 11/100\n",
            "5/5 - 0s - loss: 0.7545 - 30ms/epoch - 6ms/step\n",
            "Epoch 12/100\n",
            "5/5 - 0s - loss: 0.7291 - 21ms/epoch - 4ms/step\n",
            "Epoch 13/100\n",
            "5/5 - 0s - loss: 0.7023 - 26ms/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "5/5 - 0s - loss: 0.6788 - 23ms/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "5/5 - 0s - loss: 0.6545 - 24ms/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "5/5 - 0s - loss: 0.6319 - 25ms/epoch - 5ms/step\n",
            "Epoch 17/100\n",
            "5/5 - 0s - loss: 0.6109 - 22ms/epoch - 4ms/step\n",
            "Epoch 18/100\n",
            "5/5 - 0s - loss: 0.5888 - 24ms/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "5/5 - 0s - loss: 0.5689 - 21ms/epoch - 4ms/step\n",
            "Epoch 20/100\n",
            "5/5 - 0s - loss: 0.5496 - 22ms/epoch - 4ms/step\n",
            "Epoch 21/100\n",
            "5/5 - 0s - loss: 0.5313 - 20ms/epoch - 4ms/step\n",
            "Epoch 22/100\n",
            "5/5 - 0s - loss: 0.5162 - 21ms/epoch - 4ms/step\n",
            "Epoch 23/100\n",
            "5/5 - 0s - loss: 0.5006 - 18ms/epoch - 4ms/step\n",
            "Epoch 24/100\n",
            "5/5 - 0s - loss: 0.4861 - 22ms/epoch - 4ms/step\n",
            "Epoch 25/100\n",
            "5/5 - 0s - loss: 0.4739 - 22ms/epoch - 4ms/step\n",
            "Epoch 26/100\n",
            "5/5 - 0s - loss: 0.4619 - 25ms/epoch - 5ms/step\n",
            "Epoch 27/100\n",
            "5/5 - 0s - loss: 0.4500 - 31ms/epoch - 6ms/step\n",
            "Epoch 28/100\n",
            "5/5 - 0s - loss: 0.4389 - 25ms/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "5/5 - 0s - loss: 0.4288 - 28ms/epoch - 6ms/step\n",
            "Epoch 30/100\n",
            "5/5 - 0s - loss: 0.4193 - 27ms/epoch - 5ms/step\n",
            "Epoch 31/100\n",
            "5/5 - 0s - loss: 0.4104 - 27ms/epoch - 5ms/step\n",
            "Epoch 32/100\n",
            "5/5 - 0s - loss: 0.4021 - 21ms/epoch - 4ms/step\n",
            "Epoch 33/100\n",
            "5/5 - 0s - loss: 0.3940 - 25ms/epoch - 5ms/step\n",
            "Epoch 34/100\n",
            "5/5 - 0s - loss: 0.3864 - 27ms/epoch - 5ms/step\n",
            "Epoch 35/100\n",
            "5/5 - 0s - loss: 0.3778 - 22ms/epoch - 4ms/step\n",
            "Epoch 36/100\n",
            "5/5 - 0s - loss: 0.3705 - 19ms/epoch - 4ms/step\n",
            "Epoch 37/100\n",
            "5/5 - 0s - loss: 0.3654 - 22ms/epoch - 4ms/step\n",
            "Epoch 38/100\n",
            "5/5 - 0s - loss: 0.3561 - 21ms/epoch - 4ms/step\n",
            "Epoch 39/100\n",
            "5/5 - 0s - loss: 0.3495 - 18ms/epoch - 4ms/step\n",
            "Epoch 40/100\n",
            "5/5 - 0s - loss: 0.3435 - 18ms/epoch - 4ms/step\n",
            "Epoch 41/100\n",
            "5/5 - 0s - loss: 0.3353 - 23ms/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "5/5 - 0s - loss: 0.3299 - 27ms/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "5/5 - 0s - loss: 0.3234 - 22ms/epoch - 4ms/step\n",
            "Epoch 44/100\n",
            "5/5 - 0s - loss: 0.3165 - 19ms/epoch - 4ms/step\n",
            "Epoch 45/100\n",
            "5/5 - 0s - loss: 0.3097 - 19ms/epoch - 4ms/step\n",
            "Epoch 46/100\n",
            "5/5 - 0s - loss: 0.3043 - 18ms/epoch - 4ms/step\n",
            "Epoch 47/100\n",
            "5/5 - 0s - loss: 0.2976 - 18ms/epoch - 4ms/step\n",
            "Epoch 48/100\n",
            "5/5 - 0s - loss: 0.2905 - 17ms/epoch - 3ms/step\n",
            "Epoch 49/100\n",
            "5/5 - 0s - loss: 0.2839 - 19ms/epoch - 4ms/step\n",
            "Epoch 50/100\n",
            "5/5 - 0s - loss: 0.2773 - 21ms/epoch - 4ms/step\n",
            "Epoch 51/100\n",
            "5/5 - 0s - loss: 0.2705 - 21ms/epoch - 4ms/step\n",
            "Epoch 52/100\n",
            "5/5 - 0s - loss: 0.2642 - 21ms/epoch - 4ms/step\n",
            "Epoch 53/100\n",
            "5/5 - 0s - loss: 0.2574 - 21ms/epoch - 4ms/step\n",
            "Epoch 54/100\n",
            "5/5 - 0s - loss: 0.2509 - 21ms/epoch - 4ms/step\n",
            "Epoch 55/100\n",
            "5/5 - 0s - loss: 0.2453 - 21ms/epoch - 4ms/step\n",
            "Epoch 56/100\n",
            "5/5 - 0s - loss: 0.2387 - 19ms/epoch - 4ms/step\n",
            "Epoch 57/100\n",
            "5/5 - 0s - loss: 0.2349 - 20ms/epoch - 4ms/step\n",
            "Epoch 58/100\n",
            "5/5 - 0s - loss: 0.2263 - 22ms/epoch - 4ms/step\n",
            "Epoch 59/100\n",
            "5/5 - 0s - loss: 0.2203 - 22ms/epoch - 4ms/step\n",
            "Epoch 60/100\n",
            "5/5 - 0s - loss: 0.2159 - 22ms/epoch - 4ms/step\n",
            "Epoch 61/100\n",
            "5/5 - 0s - loss: 0.2107 - 21ms/epoch - 4ms/step\n",
            "Epoch 62/100\n",
            "5/5 - 0s - loss: 0.2044 - 21ms/epoch - 4ms/step\n",
            "Epoch 63/100\n",
            "5/5 - 0s - loss: 0.2003 - 21ms/epoch - 4ms/step\n",
            "Epoch 64/100\n",
            "5/5 - 0s - loss: 0.1950 - 21ms/epoch - 4ms/step\n",
            "Epoch 65/100\n",
            "5/5 - 0s - loss: 0.1914 - 22ms/epoch - 4ms/step\n",
            "Epoch 66/100\n",
            "5/5 - 0s - loss: 0.1878 - 23ms/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "5/5 - 0s - loss: 0.1823 - 24ms/epoch - 5ms/step\n",
            "Epoch 68/100\n",
            "5/5 - 0s - loss: 0.1781 - 32ms/epoch - 6ms/step\n",
            "Epoch 69/100\n",
            "5/5 - 0s - loss: 0.1744 - 29ms/epoch - 6ms/step\n",
            "Epoch 70/100\n",
            "5/5 - 0s - loss: 0.1694 - 27ms/epoch - 5ms/step\n",
            "Epoch 71/100\n",
            "5/5 - 0s - loss: 0.1653 - 23ms/epoch - 5ms/step\n",
            "Epoch 72/100\n",
            "5/5 - 0s - loss: 0.1630 - 20ms/epoch - 4ms/step\n",
            "Epoch 73/100\n",
            "5/5 - 0s - loss: 0.1583 - 27ms/epoch - 5ms/step\n",
            "Epoch 74/100\n",
            "5/5 - 0s - loss: 0.1547 - 19ms/epoch - 4ms/step\n",
            "Epoch 75/100\n",
            "5/5 - 0s - loss: 0.1536 - 23ms/epoch - 5ms/step\n",
            "Epoch 76/100\n",
            "5/5 - 0s - loss: 0.1485 - 24ms/epoch - 5ms/step\n",
            "Epoch 77/100\n",
            "5/5 - 0s - loss: 0.1483 - 17ms/epoch - 3ms/step\n",
            "Epoch 78/100\n",
            "5/5 - 0s - loss: 0.1433 - 17ms/epoch - 3ms/step\n",
            "Epoch 79/100\n",
            "5/5 - 0s - loss: 0.1401 - 16ms/epoch - 3ms/step\n",
            "Epoch 80/100\n",
            "5/5 - 0s - loss: 0.1379 - 16ms/epoch - 3ms/step\n",
            "Epoch 81/100\n",
            "5/5 - 0s - loss: 0.1346 - 23ms/epoch - 5ms/step\n",
            "Epoch 82/100\n",
            "5/5 - 0s - loss: 0.1356 - 18ms/epoch - 4ms/step\n",
            "Epoch 83/100\n",
            "5/5 - 0s - loss: 0.1299 - 19ms/epoch - 4ms/step\n",
            "Epoch 84/100\n",
            "5/5 - 0s - loss: 0.1292 - 18ms/epoch - 4ms/step\n",
            "Epoch 85/100\n",
            "5/5 - 0s - loss: 0.1252 - 18ms/epoch - 4ms/step\n",
            "Epoch 86/100\n",
            "5/5 - 0s - loss: 0.1233 - 20ms/epoch - 4ms/step\n",
            "Epoch 87/100\n",
            "5/5 - 0s - loss: 0.1227 - 20ms/epoch - 4ms/step\n",
            "Epoch 88/100\n",
            "5/5 - 0s - loss: 0.1191 - 19ms/epoch - 4ms/step\n",
            "Epoch 89/100\n",
            "5/5 - 0s - loss: 0.1180 - 28ms/epoch - 6ms/step\n",
            "Epoch 90/100\n",
            "5/5 - 0s - loss: 0.1151 - 28ms/epoch - 6ms/step\n",
            "Epoch 91/100\n",
            "5/5 - 0s - loss: 0.1139 - 24ms/epoch - 5ms/step\n",
            "Epoch 92/100\n",
            "5/5 - 0s - loss: 0.1116 - 23ms/epoch - 5ms/step\n",
            "Epoch 93/100\n",
            "5/5 - 0s - loss: 0.1102 - 25ms/epoch - 5ms/step\n",
            "Epoch 94/100\n",
            "5/5 - 0s - loss: 0.1086 - 24ms/epoch - 5ms/step\n",
            "Epoch 95/100\n",
            "5/5 - 0s - loss: 0.1087 - 21ms/epoch - 4ms/step\n",
            "Epoch 96/100\n",
            "5/5 - 0s - loss: 0.1041 - 21ms/epoch - 4ms/step\n",
            "Epoch 97/100\n",
            "5/5 - 0s - loss: 0.1105 - 25ms/epoch - 5ms/step\n",
            "Epoch 98/100\n",
            "5/5 - 0s - loss: 0.1064 - 29ms/epoch - 6ms/step\n",
            "Epoch 99/100\n",
            "5/5 - 0s - loss: 0.1048 - 22ms/epoch - 4ms/step\n",
            "Epoch 100/100\n",
            "5/5 - 0s - loss: 0.1003 - 22ms/epoch - 4ms/step\n",
            "5/5 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.9666666666666667\n",
            "Log loss: 0.09863957575941329\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from scipy.stats import zscore\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, log_loss, roc_curve, auc\n",
        "from sklearn import metrics\n",
        "df = pd.read_csv(\"https://data.heatonresearch.com/data/t81-558/iris.csv\", na_values=['NA', '?'])\n",
        "x_fields = []\n",
        "df[\"sepal_l\"] = MinMaxScaler().fit_transform(df[['sepal_l']])\n",
        "x_fields.append(\"sepal_l\")\n",
        "df[\"sepal_w\"] = zscore(df[\"sepal_w\"])\n",
        "x_fields.append(\"sepal_w\")\n",
        "df[\"petal_l\"] = MinMaxScaler().fit_transform(df[['petal_l']])\n",
        "x_fields.append(\"petal_l\")\n",
        "df[\"petal_w\"] = MinMaxScaler().fit_transform(df[['petal_w']])\n",
        "x_fields.append(\"petal_w\")\n",
        "x = df[x_fields].values\n",
        "dummies = pd.get_dummies(df[\"species\"])\n",
        "species = dummies.columns\n",
        "y = dummies.values\n",
        "# Construct model\n",
        "model = Sequential()\n",
        "model.add(Dense(50, input_dim=x.shape[1], activation=\"relu\"))\n",
        "model.add(Dense(25, activation=\"relu\"))\n",
        "model.add(Dense(y.shape[1], activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
        "# Train model\n",
        "model.fit(x, y, verbose=2, epochs=100)\n",
        "# Evaluate model\n",
        "pred = model.predict(x)\n",
        "predict_classes = np.argmax(pred, axis=1)\n",
        "expected_classes = np.argmax(y, axis=1)\n",
        "correct = accuracy_score(expected_classes, predict_classes)\n",
        "print(f\"Accuracy: {correct}\")\n",
        "score = metrics.log_loss(y, pred, eps=1e-07)\n",
        "print(f\"Log loss: {score}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d6d70bb",
      "metadata": {
        "id": "7d6d70bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2c4da03-4405-426b-fe75-f4a091e6655b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "16/16 - 1s - loss: 4.1126 - 710ms/epoch - 44ms/step\n",
            "Epoch 2/100\n",
            "16/16 - 0s - loss: 3.9654 - 39ms/epoch - 2ms/step\n",
            "Epoch 3/100\n",
            "16/16 - 0s - loss: 3.7613 - 52ms/epoch - 3ms/step\n",
            "Epoch 4/100\n",
            "16/16 - 0s - loss: 3.4650 - 45ms/epoch - 3ms/step\n",
            "Epoch 5/100\n",
            "16/16 - 0s - loss: 3.1506 - 43ms/epoch - 3ms/step\n",
            "Epoch 6/100\n",
            "16/16 - 0s - loss: 2.9987 - 44ms/epoch - 3ms/step\n",
            "Epoch 7/100\n",
            "16/16 - 0s - loss: 2.9034 - 36ms/epoch - 2ms/step\n",
            "Epoch 8/100\n",
            "16/16 - 0s - loss: 2.8262 - 38ms/epoch - 2ms/step\n",
            "Epoch 9/100\n",
            "16/16 - 0s - loss: 2.7594 - 37ms/epoch - 2ms/step\n",
            "Epoch 10/100\n",
            "16/16 - 0s - loss: 2.6984 - 41ms/epoch - 3ms/step\n",
            "Epoch 11/100\n",
            "16/16 - 0s - loss: 2.6423 - 45ms/epoch - 3ms/step\n",
            "Epoch 12/100\n",
            "16/16 - 0s - loss: 2.5882 - 35ms/epoch - 2ms/step\n",
            "Epoch 13/100\n",
            "16/16 - 0s - loss: 2.5386 - 44ms/epoch - 3ms/step\n",
            "Epoch 14/100\n",
            "16/16 - 0s - loss: 2.4864 - 39ms/epoch - 2ms/step\n",
            "Epoch 15/100\n",
            "16/16 - 0s - loss: 2.4410 - 36ms/epoch - 2ms/step\n",
            "Epoch 16/100\n",
            "16/16 - 0s - loss: 2.3981 - 38ms/epoch - 2ms/step\n",
            "Epoch 17/100\n",
            "16/16 - 0s - loss: 2.3526 - 38ms/epoch - 2ms/step\n",
            "Epoch 18/100\n",
            "16/16 - 0s - loss: 2.3126 - 39ms/epoch - 2ms/step\n",
            "Epoch 19/100\n",
            "16/16 - 0s - loss: 2.2747 - 34ms/epoch - 2ms/step\n",
            "Epoch 20/100\n",
            "16/16 - 0s - loss: 2.2335 - 37ms/epoch - 2ms/step\n",
            "Epoch 21/100\n",
            "16/16 - 0s - loss: 2.1967 - 35ms/epoch - 2ms/step\n",
            "Epoch 22/100\n",
            "16/16 - 0s - loss: 2.1610 - 38ms/epoch - 2ms/step\n",
            "Epoch 23/100\n",
            "16/16 - 0s - loss: 2.1248 - 34ms/epoch - 2ms/step\n",
            "Epoch 24/100\n",
            "16/16 - 0s - loss: 2.0906 - 33ms/epoch - 2ms/step\n",
            "Epoch 25/100\n",
            "16/16 - 0s - loss: 2.0599 - 34ms/epoch - 2ms/step\n",
            "Epoch 26/100\n",
            "16/16 - 0s - loss: 2.0257 - 38ms/epoch - 2ms/step\n",
            "Epoch 27/100\n",
            "16/16 - 0s - loss: 1.9968 - 42ms/epoch - 3ms/step\n",
            "Epoch 28/100\n",
            "16/16 - 0s - loss: 1.9630 - 46ms/epoch - 3ms/step\n",
            "Epoch 29/100\n",
            "16/16 - 0s - loss: 1.9334 - 32ms/epoch - 2ms/step\n",
            "Epoch 30/100\n",
            "16/16 - 0s - loss: 1.9060 - 36ms/epoch - 2ms/step\n",
            "Epoch 31/100\n",
            "16/16 - 0s - loss: 1.8804 - 34ms/epoch - 2ms/step\n",
            "Epoch 32/100\n",
            "16/16 - 0s - loss: 1.8548 - 31ms/epoch - 2ms/step\n",
            "Epoch 33/100\n",
            "16/16 - 0s - loss: 1.8293 - 30ms/epoch - 2ms/step\n",
            "Epoch 34/100\n",
            "16/16 - 0s - loss: 1.8032 - 36ms/epoch - 2ms/step\n",
            "Epoch 35/100\n",
            "16/16 - 0s - loss: 1.7752 - 32ms/epoch - 2ms/step\n",
            "Epoch 36/100\n",
            "16/16 - 0s - loss: 1.7546 - 32ms/epoch - 2ms/step\n",
            "Epoch 37/100\n",
            "16/16 - 0s - loss: 1.7301 - 32ms/epoch - 2ms/step\n",
            "Epoch 38/100\n",
            "16/16 - 0s - loss: 1.7098 - 34ms/epoch - 2ms/step\n",
            "Epoch 39/100\n",
            "16/16 - 0s - loss: 1.6856 - 34ms/epoch - 2ms/step\n",
            "Epoch 40/100\n",
            "16/16 - 0s - loss: 1.6654 - 31ms/epoch - 2ms/step\n",
            "Epoch 41/100\n",
            "16/16 - 0s - loss: 1.6448 - 30ms/epoch - 2ms/step\n",
            "Epoch 42/100\n",
            "16/16 - 0s - loss: 1.6196 - 35ms/epoch - 2ms/step\n",
            "Epoch 43/100\n",
            "16/16 - 0s - loss: 1.6016 - 32ms/epoch - 2ms/step\n",
            "Epoch 44/100\n",
            "16/16 - 0s - loss: 1.5801 - 43ms/epoch - 3ms/step\n",
            "Epoch 45/100\n",
            "16/16 - 0s - loss: 1.5617 - 33ms/epoch - 2ms/step\n",
            "Epoch 46/100\n",
            "16/16 - 0s - loss: 1.5419 - 31ms/epoch - 2ms/step\n",
            "Epoch 47/100\n",
            "16/16 - 0s - loss: 1.5269 - 33ms/epoch - 2ms/step\n",
            "Epoch 48/100\n",
            "16/16 - 0s - loss: 1.5064 - 32ms/epoch - 2ms/step\n",
            "Epoch 49/100\n",
            "16/16 - 0s - loss: 1.4857 - 30ms/epoch - 2ms/step\n",
            "Epoch 50/100\n",
            "16/16 - 0s - loss: 1.4680 - 33ms/epoch - 2ms/step\n",
            "Epoch 51/100\n",
            "16/16 - 0s - loss: 1.4508 - 31ms/epoch - 2ms/step\n",
            "Epoch 52/100\n",
            "16/16 - 0s - loss: 1.4316 - 36ms/epoch - 2ms/step\n",
            "Epoch 53/100\n",
            "16/16 - 0s - loss: 1.4154 - 35ms/epoch - 2ms/step\n",
            "Epoch 54/100\n",
            "16/16 - 0s - loss: 1.3962 - 33ms/epoch - 2ms/step\n",
            "Epoch 55/100\n",
            "16/16 - 0s - loss: 1.3787 - 35ms/epoch - 2ms/step\n",
            "Epoch 56/100\n",
            "16/16 - 0s - loss: 1.3639 - 44ms/epoch - 3ms/step\n",
            "Epoch 57/100\n",
            "16/16 - 0s - loss: 1.3453 - 33ms/epoch - 2ms/step\n",
            "Epoch 58/100\n",
            "16/16 - 0s - loss: 1.3310 - 36ms/epoch - 2ms/step\n",
            "Epoch 59/100\n",
            "16/16 - 0s - loss: 1.3130 - 32ms/epoch - 2ms/step\n",
            "Epoch 60/100\n",
            "16/16 - 0s - loss: 1.3000 - 35ms/epoch - 2ms/step\n",
            "Epoch 61/100\n",
            "16/16 - 0s - loss: 1.2870 - 31ms/epoch - 2ms/step\n",
            "Epoch 62/100\n",
            "16/16 - 0s - loss: 1.2725 - 29ms/epoch - 2ms/step\n",
            "Epoch 63/100\n",
            "16/16 - 0s - loss: 1.2547 - 30ms/epoch - 2ms/step\n",
            "Epoch 64/100\n",
            "16/16 - 0s - loss: 1.2316 - 33ms/epoch - 2ms/step\n",
            "Epoch 65/100\n",
            "16/16 - 0s - loss: 1.2169 - 31ms/epoch - 2ms/step\n",
            "Epoch 66/100\n",
            "16/16 - 0s - loss: 1.2075 - 30ms/epoch - 2ms/step\n",
            "Epoch 67/100\n",
            "16/16 - 0s - loss: 1.1889 - 30ms/epoch - 2ms/step\n",
            "Epoch 68/100\n",
            "16/16 - 0s - loss: 1.1750 - 31ms/epoch - 2ms/step\n",
            "Epoch 69/100\n",
            "16/16 - 0s - loss: 1.1662 - 31ms/epoch - 2ms/step\n",
            "Epoch 70/100\n",
            "16/16 - 0s - loss: 1.1520 - 33ms/epoch - 2ms/step\n",
            "Epoch 71/100\n",
            "16/16 - 0s - loss: 1.1326 - 36ms/epoch - 2ms/step\n",
            "Epoch 72/100\n",
            "16/16 - 0s - loss: 1.1243 - 37ms/epoch - 2ms/step\n",
            "Epoch 73/100\n",
            "16/16 - 0s - loss: 1.1073 - 36ms/epoch - 2ms/step\n",
            "Epoch 74/100\n",
            "16/16 - 0s - loss: 1.0924 - 31ms/epoch - 2ms/step\n",
            "Epoch 75/100\n",
            "16/16 - 0s - loss: 1.0846 - 33ms/epoch - 2ms/step\n",
            "Epoch 76/100\n",
            "16/16 - 0s - loss: 1.0691 - 31ms/epoch - 2ms/step\n",
            "Epoch 77/100\n",
            "16/16 - 0s - loss: 1.0588 - 34ms/epoch - 2ms/step\n",
            "Epoch 78/100\n",
            "16/16 - 0s - loss: 1.0427 - 32ms/epoch - 2ms/step\n",
            "Epoch 79/100\n",
            "16/16 - 0s - loss: 1.0304 - 32ms/epoch - 2ms/step\n",
            "Epoch 80/100\n",
            "16/16 - 0s - loss: 1.0210 - 32ms/epoch - 2ms/step\n",
            "Epoch 81/100\n",
            "16/16 - 0s - loss: 1.0093 - 33ms/epoch - 2ms/step\n",
            "Epoch 82/100\n",
            "16/16 - 0s - loss: 0.9962 - 31ms/epoch - 2ms/step\n",
            "Epoch 83/100\n",
            "16/16 - 0s - loss: 0.9839 - 33ms/epoch - 2ms/step\n",
            "Epoch 84/100\n",
            "16/16 - 0s - loss: 0.9771 - 30ms/epoch - 2ms/step\n",
            "Epoch 85/100\n",
            "16/16 - 0s - loss: 0.9671 - 39ms/epoch - 2ms/step\n",
            "Epoch 86/100\n",
            "16/16 - 0s - loss: 0.9516 - 35ms/epoch - 2ms/step\n",
            "Epoch 87/100\n",
            "16/16 - 0s - loss: 0.9424 - 34ms/epoch - 2ms/step\n",
            "Epoch 88/100\n",
            "16/16 - 0s - loss: 0.9302 - 32ms/epoch - 2ms/step\n",
            "Epoch 89/100\n",
            "16/16 - 0s - loss: 0.9209 - 30ms/epoch - 2ms/step\n",
            "Epoch 90/100\n",
            "16/16 - 0s - loss: 0.9076 - 30ms/epoch - 2ms/step\n",
            "Epoch 91/100\n",
            "16/16 - 0s - loss: 0.9015 - 33ms/epoch - 2ms/step\n",
            "Epoch 92/100\n",
            "16/16 - 0s - loss: 0.8880 - 33ms/epoch - 2ms/step\n",
            "Epoch 93/100\n",
            "16/16 - 0s - loss: 0.8796 - 33ms/epoch - 2ms/step\n",
            "Epoch 94/100\n",
            "16/16 - 0s - loss: 0.8714 - 32ms/epoch - 2ms/step\n",
            "Epoch 95/100\n",
            "16/16 - 0s - loss: 0.8596 - 32ms/epoch - 2ms/step\n",
            "Epoch 96/100\n",
            "16/16 - 0s - loss: 0.8545 - 34ms/epoch - 2ms/step\n",
            "Epoch 97/100\n",
            "16/16 - 0s - loss: 0.8403 - 40ms/epoch - 2ms/step\n",
            "Epoch 98/100\n",
            "16/16 - 0s - loss: 0.8357 - 33ms/epoch - 2ms/step\n",
            "Epoch 99/100\n",
            "16/16 - 0s - loss: 0.8208 - 37ms/epoch - 2ms/step\n",
            "Epoch 100/100\n",
            "16/16 - 0s - loss: 0.8160 - 32ms/epoch - 2ms/step\n",
            "16/16 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.8162055335968379\n",
            "Log loss: 0.7940745676326217\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from scipy.stats import zscore\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, log_loss, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.decomposition as PCA\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\", na_values=['NA', '?'])\n",
        "x_fields = []\n",
        "df[\"crim\"] = MinMaxScaler().fit_transform(df[['crim']])\n",
        "x_fields.append(\"crim\")\n",
        "df[\"crim\"] = MinMaxScaler().fit_transform(df[['crim']])\n",
        "x_fields.append(\"crim\")\n",
        "df[\"zn\"] = MinMaxScaler().fit_transform(df[['zn']])\n",
        "x_fields.append(\"zn\")\n",
        "df[\"indus\"] = MinMaxScaler().fit_transform(df[['indus']])\n",
        "x_fields.append(\"indus\")\n",
        "df[\"chas\"] = MinMaxScaler().fit_transform(df[['chas']])\n",
        "x_fields.append(\"chas\")\n",
        "df[\"nox\"] = MinMaxScaler().fit_transform(df[['nox']])\n",
        "x_fields.append(\"nox\")\n",
        "df[\"rm\"] = MinMaxScaler().fit_transform(df[['rm']])\n",
        "x_fields.append(\"rm\")\n",
        "df[\"age\"] = MinMaxScaler().fit_transform(df[['age']])\n",
        "x_fields.append(\"age\")\n",
        "df[\"dis\"] = MinMaxScaler().fit_transform(df[['dis']])\n",
        "x_fields.append(\"dis\")\n",
        "df[\"rad\"] = MinMaxScaler().fit_transform(df[['rad']])\n",
        "x_fields.append(\"rad\")\n",
        "df[\"ptratio\"] = MinMaxScaler().fit_transform(df[['ptratio']])\n",
        "x_fields.append(\"ptratio\")\n",
        "df[\"b\"] = MinMaxScaler().fit_transform(df[['b']])\n",
        "x_fields.append(\"b\")\n",
        "df[\"lstat\"] = MinMaxScaler().fit_transform(df[['lstat']])\n",
        "x_fields.append(\"lstat\")\n",
        "df[\"medv\"] = MinMaxScaler().fit_transform(df[['medv']])\n",
        "x_fields.append(\"medv\")\n",
        "x = df[x_fields].values\n",
        "dummies = pd.get_dummies(df[\"tax\"])\n",
        "species = dummies.columns\n",
        "y = dummies.values\n",
        "# Construct model\n",
        "model = Sequential()\n",
        "model.add(Dense(50, input_dim=x.shape[1], activation=\"relu\"))\n",
        "model.add(Dense(25, activation=\"relu\"))\n",
        "model.add(Dense(y.shape[1], activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
        "# Train model\n",
        "model.fit(x, y, verbose=2, epochs=100)\n",
        "# Evaluate model\n",
        "pred = model.predict(x)\n",
        "predict_classes = np.argmax(pred, axis=1)\n",
        "expected_classes = np.argmax(y, axis=1)\n",
        "correct = accuracy_score(expected_classes, predict_classes)\n",
        "print(f\"Accuracy: {correct}\")\n",
        "score = metrics.log_loss(y, pred, eps=1e-07)\n",
        "print(f\"Log loss: {score}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}